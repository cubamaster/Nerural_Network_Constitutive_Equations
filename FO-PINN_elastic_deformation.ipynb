{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67463517-7e9a-4e2f-83e0-a06858938373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 │ Total: 4.223e+01 │ PDE+comp: 8.428e-02 │ BC: 8.429e-01\n",
      "Epoch   500 │ Total: 9.903e-04 │ PDE+comp: 7.790e-04 │ BC: 4.226e-06\n",
      "Epoch  1000 │ Total: 2.044e-04 │ PDE+comp: 1.396e-04 │ BC: 1.296e-06\n",
      "Epoch  1500 │ Total: 1.182e-04 │ PDE+comp: 7.952e-05 │ BC: 7.736e-07\n",
      "Epoch  2000 │ Total: 8.740e-05 │ PDE+comp: 5.758e-05 │ BC: 5.964e-07\n",
      "Epoch  2500 │ Total: 7.224e-05 │ PDE+comp: 4.769e-05 │ BC: 4.910e-07\n",
      "Epoch  3000 │ Total: 5.841e-05 │ PDE+comp: 3.757e-05 │ BC: 4.170e-07\n",
      "Epoch  3500 │ Total: 5.069e-05 │ PDE+comp: 3.254e-05 │ BC: 3.631e-07\n",
      "Epoch  4000 │ Total: 4.953e-05 │ PDE+comp: 3.115e-05 │ BC: 3.676e-07\n",
      "Epoch  4500 │ Total: 2.384e-04 │ PDE+comp: 4.932e-05 │ BC: 3.781e-06\n",
      "Epoch  5000 │ Total: 1.521e-04 │ PDE+comp: 3.128e-05 │ BC: 2.416e-06\n",
      "Epoch  5500 │ Total: 2.513e-04 │ PDE+comp: 2.537e-05 │ BC: 4.519e-06\n",
      "Epoch  6000 │ Total: 1.689e-03 │ PDE+comp: 2.398e-05 │ BC: 3.330e-05\n",
      "Epoch  6500 │ Total: 3.443e-05 │ PDE+comp: 2.009e-05 │ BC: 2.868e-07\n",
      "Epoch  7000 │ Total: 3.180e-05 │ PDE+comp: 1.845e-05 │ BC: 2.672e-07\n",
      "Epoch  7500 │ Total: 2.413e-02 │ PDE+comp: 1.761e-05 │ BC: 4.823e-04\n",
      "Epoch  8000 │ Total: 2.397e-02 │ PDE+comp: 3.305e-05 │ BC: 4.787e-04\n",
      "Epoch  8500 │ Total: 1.045e-03 │ PDE+comp: 2.579e-05 │ BC: 2.038e-05\n",
      "Epoch  9000 │ Total: 1.312e-02 │ PDE+comp: 2.512e-05 │ BC: 2.620e-04\n",
      "Epoch  9500 │ Total: 2.623e-05 │ PDE+comp: 1.614e-05 │ BC: 2.018e-07\n",
      "✅ Model weights saved to pinn_elasticity.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "# Physical constants\n",
    "L, W = 1.0, 0.5    # domain size (cm)\n",
    "lambda_, mu = 5e9, 5e9  # elastic constants (Pa)\n",
    "h = 1.0            # thickness (cm)\n",
    "sf = 1e9           # stress scaling\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        # now outputs: u_x, u_y, E_xx, E_yy, E_xy\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # normalize into [-1,1]\n",
    "        xi  = 2.0 * x / L\n",
    "        eta = 2.0 * y / W\n",
    "\n",
    "        raw = self.net(torch.cat([xi, eta], dim=1))\n",
    "        return raw\n",
    "\n",
    "# compute true displacement gradients and small‐strain tensor via autograd\n",
    "def strain_tensor(u_net, v_net, x, y):\n",
    "    # ∂u/∂x, ∂u/∂y\n",
    "    u_x_true = torch.autograd.grad(u_net, x,\n",
    "                    grad_outputs=torch.ones_like(u_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    u_y_true = torch.autograd.grad(u_net, y,\n",
    "                    grad_outputs=torch.ones_like(u_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    # ∂v/∂x, ∂v/∂y\n",
    "    v_x_true = torch.autograd.grad(v_net, x,\n",
    "                    grad_outputs=torch.ones_like(v_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    v_y_true = torch.autograd.grad(v_net, y,\n",
    "                    grad_outputs=torch.ones_like(v_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    # small‐strain components\n",
    "    Exx = u_x_true\n",
    "    Eyy = v_y_true\n",
    "    Exy = 0.5 * (u_y_true + v_x_true)\n",
    "\n",
    "    return u_x_true, u_y_true, v_x_true, v_y_true, Exx, Eyy, Exy\n",
    "\n",
    "\n",
    "# stress from strain (unchanged)\n",
    "def stress_tensor(Exx, Eyy, Exy):\n",
    "    TrE = Exx + Eyy\n",
    "    Sxx = h * ((lambda_/sf) * TrE + 2 * (mu/sf) * Exx)\n",
    "    Syy = h * ((lambda_/sf) * TrE + 2 * (mu/sf) * Eyy)\n",
    "    Sxy = h * (2 * (mu/sf) * Exy)\n",
    "    return Sxx, Syy, Sxy\n",
    "\n",
    "\n",
    "# FO‐PINN physics loss with six‐output network: [u, v, u_x, u_y, v_x, v_y]\n",
    "def physics_loss(model, x, y):\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "\n",
    "    out = model(x, y)\n",
    "    # unpack network outputs\n",
    "    u_net, v_net, u_x_net, u_y_net, v_x_net, v_y_net = (\n",
    "        out[:,  i:i+1] for i in range(6)\n",
    "    )\n",
    "\n",
    "    # 1) true gradients & strains via autograd\n",
    "    u_x_true, u_y_true, v_x_true, v_y_true, \\\n",
    "      Exx_true, Eyy_true, Exy_true = strain_tensor(u_net, v_net, x, y)\n",
    "\n",
    "    # 2) compatibility loss\n",
    "    w_comp = 4.0\n",
    "    loss_grad = (\n",
    "        torch.mean((u_x_net - u_x_true)**2) +\n",
    "        torch.mean((u_y_net - u_y_true)**2) +\n",
    "        torch.mean((v_x_net - v_x_true)**2) +\n",
    "        torch.mean((v_y_net - v_y_true)**2)\n",
    "    )\n",
    "\n",
    "    lc = (loss_grad) * w_comp\n",
    "    \n",
    "    Exx_net, Eyy_net = u_x_net, v_y_net\n",
    "    Exy_net = 0.5 * (u_y_net + v_x_net)\n",
    "    Sxx, Syy, Sxy = stress_tensor(Exx_net, Eyy_net, Exy_net)\n",
    "\n",
    "    # 4) first‐order PDE residuals\n",
    "    Sxx_x = torch.autograd.grad(Sxx, x,\n",
    "                 grad_outputs=torch.ones_like(Sxx),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Sxy_y = torch.autograd.grad(Sxy, y,\n",
    "                 grad_outputs=torch.ones_like(Sxy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Syy_y = torch.autograd.grad(Syy, y,\n",
    "                 grad_outputs=torch.ones_like(Syy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Sxy_x = torch.autograd.grad(Sxy, x,\n",
    "                 grad_outputs=torch.ones_like(Sxy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    rx = Sxx_x + Sxy_y\n",
    "    ry = Syy_y + Sxy_x\n",
    "    lpde = torch.mean(rx**2 + ry**2)\n",
    "\n",
    "    return lpde + lc\n",
    "\n",
    "\n",
    "# BC loss\n",
    "def boundary_condition_loss(model, L, W):\n",
    "    w_A, w_D, w_C, w_B = 1.0, 1.0, 1.0, 1.0 # Weight for each \n",
    "                                            # side of the boundary condition\n",
    "    \n",
    "    # A: x = -L/2, u=v=0\n",
    "    y_A = torch.linspace(-W/2, W/2, 500).reshape(-1,1)\n",
    "    x_A = -L/2 * torch.ones_like(y_A)\n",
    "    out_A = model(x_A, y_A)\n",
    "    u_A, v_A = out_A[:,0:1], out_A[:,1:2]\n",
    "    loss_A = torch.mean(u_A**2 + v_A**2)\n",
    "    \n",
    "    # D: x = +L/2, u_x = 0.025L, u_y = 0\n",
    "    x_D = L/2 * torch.ones_like(y_A)\n",
    "    out_D = model(x_D, y_A)\n",
    "    u_D, v_D = out_D[:,2:3], out_D[:,3:4]\n",
    "    loss_D = torch.mean((u_D - 0.025*L)**2 + v_D**2)\n",
    "    \n",
    "    # C: y = -W/2 traction-free -> sigma_yy=0, sigma_xy=0\n",
    "    x_C = torch.linspace(-L/2, L/2, 200).reshape(-1,1)\n",
    "    y_C = -W/2 * torch.ones_like(x_C)\n",
    "    out_C = model(x_C, y_C)\n",
    "    Exx_C, Eyy_C = out_C[:,2:3], out_C[:,5:6]\n",
    "    Exy_C = 0.5*(out_C[:,3:4] + out_C[:,4:5])\n",
    "    _, Syy_C, Sxy_C = stress_tensor(Exx_C, Eyy_C, Exy_C)\n",
    "    loss_C = torch.mean(Syy_C**2 + Sxy_C**2)\n",
    "    \n",
    "    # B: y = +W/2 traction-free -> sigma_yy=0, sigma_xy=0\n",
    "    y_B = W/2 * torch.ones_like(x_C)\n",
    "    out_B = model(x_C, y_B)\n",
    "    Exx_B, Eyy_B = out_B[:,2:3], out_B[:,5:6]\n",
    "    Exy_B = 0.5*(out_B[:,3:4] + out_B[:,4:5])\n",
    "    _, Syy_B, Sxy_B = stress_tensor(Exx_B, Eyy_B, Exy_B)\n",
    "    loss_B = torch.mean(Syy_B**2 + Sxy_B**2)\n",
    "    return w_A*loss_A + w_D*loss_D + w_C*loss_C + w_B*loss_B\n",
    "\n",
    "\n",
    "# train \n",
    "def train_pinn(model, optimizer, n_epochs, n_points, L, W):\n",
    "    history = []\n",
    "    w_pde, w_bc = 1.0, 50.0\n",
    "\n",
    "    for ep in range(n_epochs):\n",
    "        x = torch.rand(n_points,1)*L - L/2\n",
    "        y = torch.rand(n_points,1)*W - W/2\n",
    "\n",
    "        lp = physics_loss(model, x, y)           \n",
    "        lb = boundary_condition_loss(model, L, W)  \n",
    "        loss = w_pde*lp + w_bc*lb\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        history.append(loss.item())\n",
    "        if ep % 500 == 0:\n",
    "            print(f\"Epoch {ep:5d} │ Total: {loss.item():.3e} │ PDE+comp: {lp.item():.3e} │ BC: {lb.item():.3e}\")\n",
    "    return history\n",
    "\n",
    "# initialize and run\n",
    "model     = PINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 10000\n",
    "n_points = 1000\n",
    "loss_history = train_pinn(model, optimizer, n_epochs, n_points, L, W)\n",
    "\n",
    "torch.save(model.state_dict(), \"pinn_elasticity.pth\")\n",
    "print(\"✅ Model weights saved to pinn_elasticity.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
