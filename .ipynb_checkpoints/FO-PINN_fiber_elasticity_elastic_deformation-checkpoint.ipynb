{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097c1ba8-759c-48f1-a848-0e8716b4ba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 │ Total: 9.206e+03 │ PDE+comp: 6.906e+00 │ BC: 1.840e+02\n",
      "Epoch   500 │ Total: 2.965e-01 │ PDE+comp: 1.467e-02 │ BC: 5.636e-03\n",
      "Epoch  1000 │ Total: 2.202e-01 │ PDE+comp: 7.597e-03 │ BC: 4.252e-03\n",
      "Epoch  1500 │ Total: 1.486e-01 │ PDE+comp: 3.546e-03 │ BC: 2.902e-03\n",
      "Epoch  2000 │ Total: 8.507e-02 │ PDE+comp: 1.908e-03 │ BC: 1.663e-03\n",
      "Epoch  2500 │ Total: 3.141e-02 │ PDE+comp: 2.502e-03 │ BC: 5.783e-04\n",
      "Epoch  3000 │ Total: 3.046e-02 │ PDE+comp: 1.351e-03 │ BC: 5.822e-04\n",
      "Epoch  3500 │ Total: 2.655e-02 │ PDE+comp: 1.067e-03 │ BC: 5.096e-04\n",
      "Epoch  4000 │ Total: 1.457e-02 │ PDE+comp: 1.147e-03 │ BC: 2.685e-04\n",
      "Epoch  4500 │ Total: 8.751e-03 │ PDE+comp: 1.048e-03 │ BC: 1.541e-04\n",
      "Epoch  5000 │ Total: 2.012e-02 │ PDE+comp: 9.664e-04 │ BC: 3.831e-04\n",
      "Epoch  5500 │ Total: 4.978e-03 │ PDE+comp: 8.329e-04 │ BC: 8.289e-05\n",
      "Epoch  6000 │ Total: 3.711e-02 │ PDE+comp: 7.096e-04 │ BC: 7.281e-04\n",
      "Epoch  6500 │ Total: 2.658e-03 │ PDE+comp: 6.622e-04 │ BC: 3.992e-05\n",
      "Epoch  7000 │ Total: 4.902e-03 │ PDE+comp: 6.783e-04 │ BC: 8.447e-05\n",
      "Epoch  7500 │ Total: 1.200e-01 │ PDE+comp: 5.797e-04 │ BC: 2.388e-03\n",
      "Epoch  8000 │ Total: 2.012e-03 │ PDE+comp: 5.103e-04 │ BC: 3.004e-05\n",
      "Epoch  8500 │ Total: 2.991e-03 │ PDE+comp: 8.075e-04 │ BC: 4.367e-05\n",
      "Epoch  9000 │ Total: 1.019e-03 │ PDE+comp: 4.404e-04 │ BC: 1.157e-05\n",
      "Epoch  9500 │ Total: 4.469e-03 │ PDE+comp: 5.540e-04 │ BC: 7.831e-05\n",
      "✅ Model weights saved to pinn_fiber_elasticity.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "# Physical constants\n",
    "L, W = 1.0, 0.5    # domain size (cm)\n",
    "lambda_  = 5.64e9  # elastic constants (Pa)\n",
    "mu_T = 2.46e9\n",
    "theta_deg = 30\n",
    "mu_L = 5.66e9\n",
    "alpha = 1.26e9\n",
    "beta = 227.29e9\n",
    "h = 1.0            # thickness (cm)\n",
    "sf = 1e9           # stress scaling\n",
    "\n",
    "#c\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        # now outputs: u_x, u_y, E_xx, E_yy, E_xy\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # normalize into [-1,1]\n",
    "        xi  = 2.0 * x / L\n",
    "        eta = 2.0 * y / W\n",
    "\n",
    "        raw = self.net(torch.cat([xi, eta], dim=1))\n",
    "        return raw\n",
    "\n",
    "\n",
    "#c\n",
    "# Precomputing sin and cos into tensors \n",
    "theta_rad = np.deg2rad(theta_deg) # converting degrees to rad\n",
    "c = torch.tensor(np.cos(theta_rad), dtype = torch.float32) # cos(theta)\n",
    "s = torch.tensor(np.sin(theta_rad), dtype = torch.float32) # sin(theta)\n",
    "\n",
    "# compute true displacement gradients and small‐strain tensor via autograd\n",
    "def strain_tensor(u_net, v_net, x, y):\n",
    "    # ∂u/∂x, ∂u/∂y\n",
    "    u_x_true = torch.autograd.grad(u_net, x,\n",
    "                    grad_outputs=torch.ones_like(u_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    u_y_true = torch.autograd.grad(u_net, y,\n",
    "                    grad_outputs=torch.ones_like(u_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    # ∂v/∂x, ∂v/∂y\n",
    "    v_x_true = torch.autograd.grad(v_net, x,\n",
    "                    grad_outputs=torch.ones_like(v_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    v_y_true = torch.autograd.grad(v_net, y,\n",
    "                    grad_outputs=torch.ones_like(v_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    # small‐strain components\n",
    "    Exx = u_x_true\n",
    "    Eyy = v_y_true\n",
    "    Exy = 0.5 * (u_y_true + v_x_true)\n",
    "\n",
    "    return u_x_true, u_y_true, v_x_true, v_y_true, Exx, Eyy, Exy\n",
    "\n",
    "\n",
    "# stress from strain (unchanged)\n",
    "def stress_tensor(Exx, Eyy, Exy):\n",
    "    trE = Exx + Eyy\n",
    "\n",
    "    # E a\n",
    "\n",
    "    Ea_x = Exx * c + Exy * s\n",
    "    Ea_y = Exy * c + Eyy * s\n",
    "\n",
    "    # a^T E a\n",
    "    aEa = Exx * (c*c) + 2.0 * Exy * (c * s) + Eyy * (s*s)\n",
    "\n",
    "    # tr(E)(lambdaI + alpha * axa)\n",
    "    t1_xx = trE * (lambda_ + alpha * (c*c))\n",
    "    t1_xy = trE * (alpha * c * s)\n",
    "    t1_yy = trE * (lambda_ + alpha * (s*s))\n",
    "\n",
    "    # 2* mu_T * E\n",
    "    t2_xx = 2.0 * mu_T * Exx\n",
    "    t2_xy = 2.0 * mu_T * Exy \n",
    "    t2_yy = 2.0 * mu_T * Eyy\n",
    "\n",
    "\n",
    "    # (a . Ea) * (alpha I + beta axa)\n",
    "    t3_xx = aEa * (alpha + beta * (c*c))\n",
    "    t3_xy = aEa * (beta * c * s)\n",
    "    t3_yy = aEa * (alpha + beta * (s*s))\n",
    "\n",
    "    # 2(mu_L - mu_T) * [a x Ea + E * axa]\n",
    "    A_xx = 2.0 * c * Ea_x\n",
    "    A_xy = c * Ea_y + Ea_x * s\n",
    "    A_yy = 2.0 * s * Ea_y\n",
    "    K = 2.0 * (mu_L - mu_T)\n",
    "    t4_xx = K * A_xx\n",
    "    t4_xy = K * A_xy\n",
    "    t4_yy = K * A_yy\n",
    "\n",
    "    sig_xx = t1_xx + t2_xx + t3_xx + t4_xx\n",
    "    sig_xy = t1_xy + t2_xy + t3_xy + t4_xy\n",
    "    sig_yy = t1_yy + t2_yy + t3_yy + t4_yy\n",
    "\n",
    "    Sxx = h * sig_xx / sf\n",
    "    Sxy = h * sig_xy / sf\n",
    "    Syy = h * sig_yy / sf\n",
    "    return Sxx, Syy, Sxy\n",
    "\n",
    "\n",
    "# FO‐PINN physics loss with six‐output network: [u, v, u_x, u_y, v_x, v_y]\n",
    "def physics_loss(model, x, y):\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "\n",
    "    out = model(x, y)\n",
    "    # unpack network outputs\n",
    "    u_net, v_net, u_x_net, u_y_net, v_x_net, v_y_net = (\n",
    "        out[:,  i:i+1] for i in range(6)\n",
    "    )\n",
    "\n",
    "    # 1) true gradients & strains via autograd\n",
    "    u_x_true, u_y_true, v_x_true, v_y_true, \\\n",
    "      Exx_true, Eyy_true, Exy_true = strain_tensor(u_net, v_net, x, y)\n",
    "\n",
    "    # 2) compatibility loss\n",
    "    w_comp = 1.0\n",
    "    loss_grad = (\n",
    "        torch.mean((u_x_net - u_x_true)**2) +\n",
    "        torch.mean((u_y_net - u_y_true)**2) +\n",
    "        torch.mean((v_x_net - v_x_true)**2) +\n",
    "        torch.mean((v_y_net - v_y_true)**2)\n",
    "    )\n",
    "\n",
    "    lc = (loss_grad) * w_comp\n",
    "    \n",
    "    Exx_net, Eyy_net = u_x_net, v_y_net\n",
    "    Exy_net = 0.5 * (u_y_net + v_x_net)\n",
    "    Sxx, Syy, Sxy = stress_tensor(Exx_net, Eyy_net, Exy_net)\n",
    "\n",
    "    # 4) first‐order PDE residuals\n",
    "    Sxx_x = torch.autograd.grad(Sxx, x,\n",
    "                 grad_outputs=torch.ones_like(Sxx),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Sxy_y = torch.autograd.grad(Sxy, y,\n",
    "                 grad_outputs=torch.ones_like(Sxy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Syy_y = torch.autograd.grad(Syy, y,\n",
    "                 grad_outputs=torch.ones_like(Syy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Sxy_x = torch.autograd.grad(Sxy, x,\n",
    "                 grad_outputs=torch.ones_like(Sxy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    rx = Sxx_x + Sxy_y\n",
    "    ry = Syy_y + Sxy_x\n",
    "    lpde = torch.mean(rx**2 + ry**2)\n",
    "\n",
    "    return lpde + lc\n",
    "\n",
    "\n",
    "# BC loss\n",
    "def boundary_condition_loss(model, L, W):\n",
    "    w_A, w_D, w_C, w_B = 1.0, 1.0, 1.0, 1.0 # Weight for each \n",
    "                                            # side of the boundary condition\n",
    "    \n",
    "    # A: x = -L/2, u=v=0\n",
    "    y_A = torch.linspace(-W/2, W/2, 500).reshape(-1,1)\n",
    "    x_A = -L/2 * torch.ones_like(y_A)\n",
    "    out_A = model(x_A, y_A)\n",
    "    u_A, v_A = out_A[:,0:1], out_A[:,1:2]\n",
    "    loss_A = torch.mean(u_A**2 + v_A**2)\n",
    "    \n",
    "    # D: x = +L/2, u_x = 0.025L, u_y = 0\n",
    "    x_D = L/2 * torch.ones_like(y_A)\n",
    "    out_D = model(x_D, y_A)\n",
    "    u_D, v_D = out_D[:,2:3], out_D[:,3:4]\n",
    "    loss_D = torch.mean((u_D - 0.02*L)**2 + v_D**2)\n",
    "    \n",
    "    # C: y = -W/2 traction-free -> sigma_yy=0, sigma_xy=0\n",
    "    x_C = torch.linspace(-L/2, L/2, 200).reshape(-1,1)\n",
    "    y_C = -W/2 * torch.ones_like(x_C)\n",
    "    out_C = model(x_C, y_C)\n",
    "    Exx_C, Eyy_C = out_C[:,2:3], out_C[:,5:6]\n",
    "    Exy_C = 0.5*(out_C[:,3:4] + out_C[:,4:5])\n",
    "    _, Syy_C, Sxy_C = stress_tensor(Exx_C, Eyy_C, Exy_C)\n",
    "    loss_C = torch.mean(Syy_C**2 + Sxy_C**2)\n",
    "    \n",
    "    # B: y = +W/2 traction-free -> sigma_yy=0, sigma_xy=0\n",
    "    y_B = W/2 * torch.ones_like(x_C)\n",
    "    out_B = model(x_C, y_B)\n",
    "    Exx_B, Eyy_B = out_B[:,2:3], out_B[:,5:6]\n",
    "    Exy_B = 0.5*(out_B[:,3:4] + out_B[:,4:5])\n",
    "    _, Syy_B, Sxy_B = stress_tensor(Exx_B, Eyy_B, Exy_B)\n",
    "    loss_B = torch.mean(Syy_B**2 + Sxy_B**2)\n",
    "    return w_A*loss_A + w_D*loss_D + w_C*loss_C + w_B*loss_B\n",
    "\n",
    "\n",
    "# train \n",
    "def train_pinn(model, optimizer, n_epochs, n_points, L, W):\n",
    "    history = []\n",
    "    w_pde, w_bc = 1.0, 50.0\n",
    "\n",
    "    for ep in range(n_epochs):\n",
    "        x = torch.rand(n_points,1)*L - L/2\n",
    "        y = torch.rand(n_points,1)*W - W/2\n",
    "\n",
    "        lp = physics_loss(model, x, y)           \n",
    "        lb = boundary_condition_loss(model, L, W)  \n",
    "        loss = w_pde*lp + w_bc*lb\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        history.append(loss.item())\n",
    "        if ep % 500 == 0:\n",
    "            print(f\"Epoch {ep:5d} │ Total: {loss.item():.3e} │ PDE+comp: {lp.item():.3e} │ BC: {lb.item():.3e}\")\n",
    "    return history\n",
    "\n",
    "# initialize and run\n",
    "model     = PINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 10000\n",
    "n_points = 1000\n",
    "loss_history = train_pinn(model, optimizer, n_epochs, n_points, L, W)\n",
    "\n",
    "torch.save(model.state_dict(), \"pinn_fiber_elasticity.pth\")\n",
    "print(\"✅ Model weights saved to pinn_fiber_elasticity.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c0450-8896-43f4-9ff3-72d1f06ed6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
