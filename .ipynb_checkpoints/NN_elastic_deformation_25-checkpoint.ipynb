{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c3606a-3f94-4a29-8e0f-b6deb70a6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181e7fbd-06ba-46fa-91d0-979769fa58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "L, W = 0.01, 0.005  # Length and width of the domain (in m)\n",
    "lambda_ = 5.0e9   # Elastic constant (Pa)\n",
    "mu = 5.0e9         # Shear modulus (Pa)\n",
    "h = 0.01          # Thickness (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e33e1d4-9b51-4c24-bbff-1b43375fb73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        inputs = torch.cat([x, y], dim=1)\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561c895f-668d-473a-ae58-df22fe2bb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain_tensor(u_x, u_y, x, y):\n",
    "    u_x_x = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "    u_y_y = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
    "    u_x_y = torch.autograd.grad(u_x, y, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "    u_y_x = torch.autograd.grad(u_y, x, grad_outputs=torch.ones_like(u_y), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    E_xx = u_x_x\n",
    "    E_yy = u_y_y\n",
    "    E_xy = 0.5 * (u_x_y + u_y_x)\n",
    "    return E_xx, E_yy, E_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b93b287-b084-443f-ac41-6accfaebf7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stress_tensor(E_xx, E_yy, E_xy):\n",
    "    scale_factor = 1e9  # Scaling factor for material constants\n",
    "    trace_E = E_xx + E_yy\n",
    "    sigma_xx = h * ((lambda_ / scale_factor) * trace_E + 2 * (mu / scale_factor) * E_xx)\n",
    "    sigma_yy = h * ((lambda_ / scale_factor) * trace_E + 2 * (mu / scale_factor) * E_yy)\n",
    "    sigma_xy = h * (2 * (mu / scale_factor) * E_xy)\n",
    "    return sigma_xx, sigma_yy, sigma_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a208f476-1550-4711-9b88-aca920d8a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss(model, x, y):\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "    u = model(x, y)\n",
    "    u_x, u_y = u[:, 0:1], u[:, 1:2]\n",
    "\n",
    "    E_xx, E_yy, E_xy = strain_tensor(u_x, u_y, x, y)\n",
    "    sigma_xx, sigma_yy, sigma_xy = stress_tensor(E_xx, E_yy, E_xy)\n",
    "\n",
    "    sigma_xx_x = torch.autograd.grad(sigma_xx, x, grad_outputs=torch.ones_like(sigma_xx), retain_graph=True, create_graph=True)[0]\n",
    "    sigma_xy_y = torch.autograd.grad(sigma_xy, y, grad_outputs=torch.ones_like(sigma_xy), retain_graph=True, create_graph=True)[0]\n",
    "    sigma_yy_y = torch.autograd.grad(sigma_yy, y, grad_outputs=torch.ones_like(sigma_yy), retain_graph=True, create_graph=True)[0]\n",
    "    sigma_xy_x = torch.autograd.grad(sigma_xy, x, grad_outputs=torch.ones_like(sigma_xy), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    residual_x = sigma_xx_x + sigma_xy_y\n",
    "    residual_y = sigma_yy_y + sigma_xy_x\n",
    "\n",
    "    loss_equilibrium = torch.mean(residual_x**2 + residual_y**2)\n",
    "    return loss_equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eadf39c-ef2f-4ae8-815a-928779a977f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_condition_loss(model, L, W):\n",
    "    # Boundary A: u_x = 0, u_y = 0 at x = -L/2\n",
    "    y_A = torch.linspace(-W / 2, W / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    u_A = model(-L / 2 * torch.ones_like(y_A, requires_grad=True), y_A)\n",
    "    loss_A = torch.mean(u_A**2)\n",
    "\n",
    "    # Boundary D: u_x = 0.025 * L, u_y = 0 at x = L/2\n",
    "    y_D = torch.linspace(-W / 2, W / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    u_D = model(L / 2 * torch.ones_like(y_D, requires_grad=True), y_D)\n",
    "    loss_D = torch.mean((u_D[:, 1:2]**2) + (u_D[:, 0:1] - 0.025 * L)**2)\n",
    "\n",
    "    # Boundary B: traction-free (ﾏダxx = ﾏダxy = 0) at y = W/2\n",
    "    x_B = torch.linspace(-L / 2, L / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    y_B = W / 2 * torch.ones_like(x_B, requires_grad=True)\n",
    "    u_B = model(x_B, y_B)\n",
    "    u_B_x, u_B_y = u_B[:, 0:1], u_B[:, 1:2]\n",
    "    E_xx_B, E_yy_B, E_xy_B = strain_tensor(u_B_x, u_B_y, x_B, y_B)\n",
    "    sigma_xx_B, sigma_yy_B, sigma_xy_B = stress_tensor(E_xx_B, E_yy_B, E_xy_B)\n",
    "    loss_B = torch.mean(sigma_yy_B**2 +sigma_xy_B**2)\n",
    "\n",
    "    # Boundary C: traction-free (ﾏダxx = ﾏダxy = 0) at y = -W/2\n",
    "    x_C = torch.linspace(-L / 2, L / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    y_C = -W / 2 * torch.ones_like(x_C, requires_grad=True)\n",
    "    u_C = model(x_C, y_C)\n",
    "    u_C_x, u_C_y = u_C[:, 0:1], u_C[:, 1:2]\n",
    "    E_xx_C, E_yy_C, E_xy_C = strain_tensor(u_C_x, u_C_y, x_C, y_C)\n",
    "    sigma_xx_C, sigma_yy_C, sigma_xy_C = stress_tensor(E_xx_C, E_yy_C, E_xy_C)\n",
    "    loss_C = torch.mean(sigma_yy_C**2 + sigma_xy_C**2)\n",
    "\n",
    "    return loss_A + loss_D + loss_B / 1e18  + loss_C / 1e18 # later divide B and C by 10**18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646e2c36-4bbd-4006-9ccc-36f89d15c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn_two_phases(model, optimizer,\n",
    "                          n_epochs_phase1, n_epochs_phase2,\n",
    "                          n_points, L, W,\n",
    "                          pde_weight_phase2=0.01):\n",
    "    \"\"\"\n",
    "    Phase I: PDE emphasis (ignore or lightly weight BC).\n",
    "    Phase II: BC emphasis + small PDE penalty (pde_weight_phase2).\n",
    "    \"\"\"\n",
    "    pde_loss_hist = []\n",
    "    bc_loss_hist = []\n",
    "\n",
    "    # -- Phase I: PDE Focus --\n",
    "    for epoch in range(n_epochs_phase1):\n",
    "        # Sample interior points\n",
    "        x = torch.rand((n_points, 1)) * L - L/2\n",
    "        y = torch.rand((n_points, 1)) * W - W/2\n",
    "\n",
    "        loss_pde = physics_loss(model, x, y)\n",
    "        loss_total = loss_pde  # BC not included or very tiny weight\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pde_loss_hist.append(loss_pde.item())\n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"[Phase I, Epoch {epoch}] PDE Loss: {loss_pde.item():.3e}\")\n",
    "\n",
    "    # -- Phase II: BC Focus (plus small PDE penalty) --\n",
    "    for epoch in range(n_epochs_phase2):\n",
    "        x = torch.rand((n_points, 1)) * L - L/2\n",
    "        y = torch.rand((n_points, 1)) * W - W/2\n",
    "\n",
    "        loss_bc = boundary_condition_loss(model, L, W)\n",
    "        loss_pde = physics_loss(model, x, y)\n",
    "\n",
    "        loss_total = loss_bc + pde_weight_phase2 * loss_pde\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bc_loss_hist.append(loss_bc.item())\n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"[Phase II, Epoch {epoch}] BC Loss: {loss_bc.item():.3e}, PDE Loss: {loss_pde.item():.3e}\")\n",
    "\n",
    "    return pde_loss_hist, bc_loss_hist\n",
    "\n",
    "def train_pinn_combined(model, optimizer, n_epochs, n_points, L, W, alpha=1.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    Single-phase training that combines PDE (alpha * PDE) and BC (beta * BC).\n",
    "    \"\"\"\n",
    "    history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        x = torch.rand((n_points, 1)) * L - L/2\n",
    "        y = torch.rand((n_points, 1)) * W - W/2\n",
    "\n",
    "        loss_pde = physics_loss(model, x, y)\n",
    "        loss_bc = boundary_condition_loss(model, L, W)\n",
    "        loss_total = alpha * loss_pde + beta * loss_bc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        history.append(loss_total.item())\n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"[Phase III, Epoch {epoch}] PDE Loss: {loss_pde.item():.3e}, BC Loss: {loss_bc.item():.3e}, Total: {loss_total.item():.3e}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dadc0d1-0141-497a-b781-2357697713ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Phase I, Epoch 0] PDE Loss: 7.309393e-05\n",
      "[Phase I, Epoch 500] PDE Loss: 8.432555e-11\n",
      "[Phase I, Epoch 1000] PDE Loss: 4.099519e-11\n",
      "[Phase I, Epoch 1500] PDE Loss: 5.177687e-11\n",
      "[Phase I, Epoch 2000] PDE Loss: 3.587616e-12\n",
      "[Phase I, Epoch 2500] PDE Loss: 1.794371e-12\n",
      "[Phase I, Epoch 3000] PDE Loss: 7.781887e-13\n",
      "[Phase I, Epoch 3500] PDE Loss: 5.599552e-10\n",
      "[Phase I, Epoch 4000] PDE Loss: 1.587144e-12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m n_epochs_phase1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m      9\u001b[0m n_epochs_phase2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m---> 10\u001b[0m pde_loss_hist, bc_loss_hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_pinn_two_phases\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs_phase1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs_phase2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mtrain_pinn_two_phases\u001b[0;34m(model, optimizer, n_epochs_phase1, n_epochs_phase2, n_points, L, W)\u001b[0m\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((n_points, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m L \u001b[38;5;241m-\u001b[39m L\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((n_points, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m W \u001b[38;5;241m-\u001b[39m W\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 13\u001b[0m loss_pde \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Since we do PDE-only, ignore BC or set it extremely low weight\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# e.g. loss_total = loss_pde + epsilon * loss_bc\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss_total \u001b[38;5;241m=\u001b[39m loss_pde\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m sigma_xx, sigma_yy, sigma_xy \u001b[38;5;241m=\u001b[39m stress_tensor(E_xx, E_yy, E_xy)\n\u001b[1;32m     10\u001b[0m sigma_xx_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(sigma_xx, x, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(sigma_xx), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m sigma_xy_y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_xy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m sigma_yy_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(sigma_yy, y, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(sigma_yy), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m sigma_xy_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(sigma_xy, x, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(sigma_xy), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:436\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    432\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    433\u001b[0m         grad_outputs_\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    447\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    449\u001b[0m     ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # Phase settings\n",
    "    n_points = 1000\n",
    "    n_epochs_phase1 = 3000\n",
    "    n_epochs_phase2 = 3000\n",
    "\n",
    "    # 1) Phase I & II: Two-Stage Training\n",
    "    print(\"=== Starting Phase I & II ===\")\n",
    "    pde_loss_hist, bc_loss_hist = train_pinn_two_phases(\n",
    "        model, optimizer,\n",
    "        n_epochs_phase1, n_epochs_phase2,\n",
    "        n_points, L, W,\n",
    "        pde_weight_phase2=0.01  # how strongly PDE is enforced in Phase II\n",
    "    )\n",
    "\n",
    "    # 2) Phase III: Combined Refinement (optional)\n",
    "    print(\"\\n=== Starting Phase III (Combined PDE+BC) ===\")\n",
    "    n_epochs_phase3 = 2000\n",
    "    alpha = 1.0\n",
    "    beta = 1.0\n",
    "    combined_history = train_pinn_combined(\n",
    "        model, optimizer, n_epochs_phase3, n_points, L, W,\n",
    "        alpha=alpha, beta=beta\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c5e5af3-b553-40be-9426-f7fe4dcc9396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Phase I, Epoch 0] PDE Loss: 7.309393e-05\n",
      "[Phase I, Epoch 500] PDE Loss: 8.432555e-11\n",
      "[Phase I, Epoch 1000] PDE Loss: 4.099519e-11\n",
      "[Phase I, Epoch 1500] PDE Loss: 5.177687e-11\n",
      "[Phase I, Epoch 2000] PDE Loss: 3.587616e-12\n",
      "[Phase I, Epoch 2500] PDE Loss: 1.794371e-12\n",
      "[Phase I, Epoch 3000] PDE Loss: 7.781887e-13\n",
      "[Phase I, Epoch 3500] PDE Loss: 5.599552e-10\n",
      "[Phase I, Epoch 4000] PDE Loss: 1.587144e-12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m n_epochs_phase1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m      9\u001b[0m n_epochs_phase2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m---> 10\u001b[0m pde_loss_hist, bc_loss_hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_pinn_two_phases\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs_phase1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs_phase2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mtrain_pinn_two_phases\u001b[0;34m(model, optimizer, n_epochs_phase1, n_epochs_phase2, n_points, L, W)\u001b[0m\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((n_points, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m L \u001b[38;5;241m-\u001b[39m L\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((n_points, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m W \u001b[38;5;241m-\u001b[39m W\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 13\u001b[0m loss_pde \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Since we do PDE-only, ignore BC or set it extremely low weight\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# e.g. loss_total = loss_pde + epsilon * loss_bc\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss_total \u001b[38;5;241m=\u001b[39m loss_pde\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m sigma_xx, sigma_yy, sigma_xy \u001b[38;5;241m=\u001b[39m stress_tensor(E_xx, E_yy, E_xy)\n\u001b[1;32m     10\u001b[0m sigma_xx_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(sigma_xx, x, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(sigma_xx), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m sigma_xy_y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_xy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m sigma_yy_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(sigma_yy, y, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(sigma_yy), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m sigma_xy_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(sigma_xy, x, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(sigma_xy), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:436\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    432\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    433\u001b[0m         grad_outputs_\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    447\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    449\u001b[0m     ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "torch.set_default_dtype(torch.float64)\n",
    "model = PINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model in two phases\n",
    "n_points = 1000\n",
    "n_epochs_phase1 = 5000\n",
    "n_epochs_phase2 = 5000\n",
    "pde_loss_hist, bc_loss_hist = train_pinn_two_phases(\n",
    "    model, optimizer, n_epochs_phase1, n_epochs_phase2, n_points, L, W\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b164484-0244-47c1-956c-d4cf85455a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdce1d-d634-4c7d-b06d-71bf19e1762b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb79f1-97d2-48a1-9e5b-ee09b3aeb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a0a0c-199d-49c0-a067-f5f40bd168c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/murat/Downloads/data.csv'  # Update this with the correct path\n",
    "comparison_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d198ea-be36-4a43-9414-c72a704ed5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = torch.tensor(comparison_data['X'].values, dtype=torch.float32).reshape(-1, 1)\n",
    "y_values = torch.tensor(comparison_data['Y'].values, dtype=torch.float32).reshape(-1, 1)\n",
    "u_x_actual = comparison_data['u_x_actual'].values\n",
    "u_y_actual = comparison_data['u_y_actual'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9d85f-6036-4574-af62-54ee17c4bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    u_pred = model(x_values, y_values) \n",
    "    u_x_pred = u_pred[:, 0].reshape(-1).numpy()\n",
    "    u_y_pred = u_pred[:, 1].reshape(-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad8dd91-58c6-4082-b968-26bfe14573cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data['u_x_pred'] = u_x_pred\n",
    "comparison_data['u_y_pred'] = u_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea552258-7b20-441a-bae9-899ab8cb06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data['error_u_x'] = abs(comparison_data['u_x_actual'] - comparison_data['u_x_pred'])\n",
    "comparison_data['error_u_y'] = abs(comparison_data['u_y_actual'] - comparison_data['u_y_pred'])\n",
    "comparison_data['percent_error_u_x'] = abs(comparison_data['u_x_actual'] - comparison_data['u_x_pred']) / abs(comparison_data['u_x_actual'])\n",
    "comparison_data['percent_error_u_y'] = abs(comparison_data['u_y_actual'] - comparison_data['u_y_pred']) / abs(comparison_data['u_y_actual'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea09621-bd1e-4c17-bd6d-4a9eee9dd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comparison_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415d15b-abb0-4153-b9c8-eef4d21a60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data.to_csv('/Users/murat/Downloads/comparison_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176ff2e-483f-4c60-a26c-eac2caa7e99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
