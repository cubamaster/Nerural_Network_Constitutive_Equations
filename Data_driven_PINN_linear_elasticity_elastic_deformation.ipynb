{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73135f8-b8ea-4e99-b133-a3490c129ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.tri as mtri\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Physical constants\n",
    "L, W = 1.0, 0.5    # domain size (cm)\n",
    "lambda_, mu = 5e9, 5e9  # elastic constants (Pa)\n",
    "h = 1.0            # thickness (cm)\n",
    "sf = 1e9           # stress scaling\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        # now outputs: u_x, u_y, E_xx, E_yy, E_xy\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # normalize into [-1,1]\n",
    "        xi  = 2.0 * x / L\n",
    "        eta = 2.0 * y / W\n",
    "\n",
    "        raw = self.net(torch.cat([xi, eta], dim=1))\n",
    "        return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d7ba3d-0012-4c6d-afcf-32bd423e025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute true displacement gradients and small‐strain tensor via autograd\n",
    "def strain_tensor(u_net, v_net, x, y):\n",
    "    # ∂u/∂x, ∂u/∂y\n",
    "    u_x_true = torch.autograd.grad(u_net, x,\n",
    "                    grad_outputs=torch.ones_like(u_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    u_y_true = torch.autograd.grad(u_net, y,\n",
    "                    grad_outputs=torch.ones_like(u_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    # ∂v/∂x, ∂v/∂y\n",
    "    v_x_true = torch.autograd.grad(v_net, x,\n",
    "                    grad_outputs=torch.ones_like(v_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "    v_y_true = torch.autograd.grad(v_net, y,\n",
    "                    grad_outputs=torch.ones_like(v_net),\n",
    "                    retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    # small‐strain components\n",
    "    Exx = u_x_true\n",
    "    Eyy = v_y_true\n",
    "    Exy = 0.5 * (u_y_true + v_x_true)\n",
    "\n",
    "    return u_x_true, u_y_true, v_x_true, v_y_true, Exx, Eyy, Exy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f525ec6-128c-48ad-a6ac-723e635e97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stress from strain (unchanged)\n",
    "def stress_tensor(Exx, Eyy, Exy):\n",
    "    TrE = Exx + Eyy\n",
    "    Sxx = h * ((lambda_/sf) * TrE + 2 * (mu/sf) * Exx)\n",
    "    Syy = h * ((lambda_/sf) * TrE + 2 * (mu/sf) * Eyy)\n",
    "    Sxy = h * (2 * (mu/sf) * Exy)\n",
    "    return Sxx, Syy, Sxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83adaef2-9c00-4a0e-b6b9-887de50c0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FO‐PINN physics loss with six‐output network: [u, v, u_x, u_y, v_x, v_y]\n",
    "def physics_loss(model, x, y):\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "\n",
    "    out = model(x, y)\n",
    "    # unpack network outputs\n",
    "    u_net, v_net, u_x_net, u_y_net, v_x_net, v_y_net = (\n",
    "        out[:,  i:i+1] for i in range(6)\n",
    "    )\n",
    "\n",
    "    # 1) true gradients & strains via autograd\n",
    "    u_x_true, u_y_true, v_x_true, v_y_true, \\\n",
    "      Exx_true, Eyy_true, Exy_true = strain_tensor(u_net, v_net, x, y)\n",
    "\n",
    "    # 2) compatibility loss\n",
    "    w_comp = 1.0\n",
    "    loss_grad = (\n",
    "        torch.mean((u_x_net - u_x_true)**2) +\n",
    "        torch.mean((u_y_net - u_y_true)**2) +\n",
    "        torch.mean((v_x_net - v_x_true)**2) +\n",
    "        torch.mean((v_y_net - v_y_true)**2)\n",
    "    )\n",
    "\n",
    "    lc = (loss_grad) * w_comp\n",
    "    \n",
    "    Exx_net, Eyy_net = u_x_net, v_y_net\n",
    "    Exy_net = 0.5 * (u_y_net + v_x_net)\n",
    "    Sxx, Syy, Sxy = stress_tensor(Exx_net, Eyy_net, Exy_net)\n",
    "\n",
    "    # 4) first‐order PDE residuals\n",
    "    Sxx_x = torch.autograd.grad(Sxx, x,\n",
    "                 grad_outputs=torch.ones_like(Sxx),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Sxy_y = torch.autograd.grad(Sxy, y,\n",
    "                 grad_outputs=torch.ones_like(Sxy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Syy_y = torch.autograd.grad(Syy, y,\n",
    "                 grad_outputs=torch.ones_like(Syy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "    Sxy_x = torch.autograd.grad(Sxy, x,\n",
    "                 grad_outputs=torch.ones_like(Sxy),\n",
    "                 retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    rx = Sxx_x + Sxy_y\n",
    "    ry = Syy_y + Sxy_x\n",
    "    lpde = torch.mean(rx**2 + ry**2)\n",
    "\n",
    "    return lpde + lc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027385e5-9f52-47ab-b57e-3f6d674184cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC loss\n",
    "def boundary_condition_loss(model, L, W):\n",
    "    w_A, w_D, w_C, w_B = 1.0, 1.0, 1.0, 1.0 # Weight for each \n",
    "                                            # side of the boundary condition\n",
    "    \n",
    "    # A: x = -L/2, u=v=0\n",
    "    y_A = torch.linspace(-W/2, W/2, 500).reshape(-1,1)\n",
    "    x_A = -L/2 * torch.ones_like(y_A)\n",
    "    out_A = model(x_A, y_A)\n",
    "    u_A, v_A = out_A[:,0:1], out_A[:,1:2]\n",
    "    loss_A = torch.mean(u_A**2 + v_A**2)\n",
    "    \n",
    "    # D: x = +L/2, u_x = 0.025L, u_y = 0\n",
    "    x_D = L/2 * torch.ones_like(y_A)\n",
    "    out_D = model(x_D, y_A)\n",
    "    u_D, v_D = out_D[:,2:3], out_D[:,3:4]\n",
    "    loss_D = torch.mean((u_D - 0.02*L)**2 + v_D**2)\n",
    "    \n",
    "    # C: y = -W/2 traction-free -> sigma_yy=0, sigma_xy=0\n",
    "    x_C = torch.linspace(-L/2, L/2, 200).reshape(-1,1)\n",
    "    y_C = -W/2 * torch.ones_like(x_C)\n",
    "    out_C = model(x_C, y_C)\n",
    "    Exx_C, Eyy_C = out_C[:,2:3], out_C[:,5:6]\n",
    "    Exy_C = 0.5*(out_C[:,3:4] + out_C[:,4:5])\n",
    "    _, Syy_C, Sxy_C = stress_tensor(Exx_C, Eyy_C, Exy_C)\n",
    "    loss_C = torch.mean(Syy_C**2 + Sxy_C**2)\n",
    "    \n",
    "    # B: y = +W/2 traction-free -> sigma_yy=0, sigma_xy=0\n",
    "    y_B = W/2 * torch.ones_like(x_C)\n",
    "    out_B = model(x_C, y_B)\n",
    "    Exx_B, Eyy_B = out_B[:,2:3], out_B[:,5:6]\n",
    "    Exy_B = 0.5*(out_B[:,3:4] + out_B[:,4:5])\n",
    "    _, Syy_B, Sxy_B = stress_tensor(Exx_B, Eyy_B, Exy_B)\n",
    "    loss_B = torch.mean(Syy_B**2 + Sxy_B**2)\n",
    "    return w_A*loss_A + w_D*loss_D + w_C*loss_C + w_B*loss_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16823a7e-52c4-41f4-b2fd-b28b50e6ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV and convert to Tensor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype  = torch.float32\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def load_fea_dataframe(path):\n",
    "    \"\"\"Robustly parse COMSOL CSV that has a text preamble.\"\"\"\n",
    "    raw = pd.read_csv(path, header=None)\n",
    "    header_row = None\n",
    "    for i in range(min(200, len(raw))):\n",
    "        row = raw.iloc[i].astype(str).tolist()\n",
    "        if (\"X\" in row) and (\"Y\" in row):\n",
    "            header_row = i\n",
    "            break\n",
    "    if header_row is None:\n",
    "        raise ValueError(\"Could not locate header row with X,Y.\")\n",
    "    df = pd.read_csv(path, header=header_row).dropna(axis=1, how='all')\n",
    "    return df\n",
    "\n",
    "def fea_to_tensors(df, device, dtype):\n",
    "    \"\"\"Return dict of torch tensors (None if column is missing).\"\"\"\n",
    "    def maybe(name, reshape=True):\n",
    "        if name in df.columns:\n",
    "            a = torch.tensor(df[name].to_numpy(), dtype=dtype, device=device)\n",
    "            return a.view(-1,1) if reshape else a\n",
    "        return None\n",
    "\n",
    "    tens = {\n",
    "        \"X\":   maybe(\"X\"),\n",
    "        \"Y\":   maybe(\"Y\"),\n",
    "        \"U\":   maybe(\"u1 (cm)\"),\n",
    "        \"V\":   maybe(\"u2 (cm)\"),\n",
    "        \"E11\": maybe(\"E11 (1)\"),\n",
    "        \"E22\": maybe(\"E22 (1)\"),\n",
    "        \"E12\": maybe(\"E12 (1)\"),\n",
    "    }\n",
    "    # filter rows that have X,Y \n",
    "    mask = torch.ones(len(df), dtype=torch.bool)\n",
    "    for k in (\"X\",\"Y\",\"U\",\"V\"):\n",
    "        if tens[k] is None:\n",
    "            raise ValueError(f\"CSV missing required column: {k}\")\n",
    "        mask &= ~torch.isnan(tens[k].view(-1))\n",
    "    for k,v in tens.items():\n",
    "        tens[k] = v[mask] if v is not None else None\n",
    "    return tens\n",
    "\n",
    "class FEADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tens):\n",
    "        self.t = tens\n",
    "        self.n = self.t[\"X\"].shape[0]\n",
    "    def __len__(self): return self.n\n",
    "    def __getitem__(self, i):\n",
    "        return {k: (v[i:i+1] if v is not None else None) for k,v in self.t.items()}\n",
    "\n",
    "def collate_dict(batch_list):\n",
    "    keys = batch_list[0].keys()\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        vals = [b[k] for b in batch_list if b[k] is not None]\n",
    "        out[k] = torch.cat(vals, dim=0) if vals else None\n",
    "    return out\n",
    "\n",
    "# --- load CSV file with DATA from COMSOL-\n",
    "df  = load_fea_dataframe(\"/Users/murat/Downloads/data.csv\")\n",
    "if \"L (cm)\" in df.columns: L = float(df[\"L (cm)\"].iloc[0])\n",
    "if \"W (cm)\" in df.columns: W = float(df[\"W (cm)\"].iloc[0])\n",
    "\n",
    "fea_t = fea_to_tensors(df, device, dtype)\n",
    "train_ds = FEADataset(fea_t)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=2048, shuffle=True, collate_fn=collate_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eca05c76-6fb1-4f29-bf3a-34cd6d416bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised data loss\n",
    "def data_loss_uvE(model, batch, weights=None):\n",
    "    \"\"\"\n",
    "    Supervised loss using CSV pairs at the exact (X,Y).\n",
    "    weights = {\"u\":1.0, \"E\":1.0} \n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {\"u\": 1.0, \"E\": 1.0}\n",
    "\n",
    "    Xb, Yb = batch[\"X\"], batch[\"Y\"]\n",
    "    Ub, Vb = batch[\"U\"], batch[\"V\"]\n",
    "    E11b, E22b, E12b = batch.get(\"E11\"), batch.get(\"E22\"), batch.get(\"E12\")\n",
    "\n",
    "    out = model(Xb, Yb)\n",
    "    u_pred, v_pred, ux_pred, uy_pred, vx_pred, vy_pred = (out[:,i:i+1] for i in range(6))\n",
    "\n",
    "    loss = torch.zeros(1, device=out.device, dtype=out.dtype)\n",
    "\n",
    "    # Displacements\n",
    "    if weights.get(\"u\", 0.0) > 0:\n",
    "        Lu = torch.mean((u_pred - Ub)**2 + (v_pred - Vb)**2)\n",
    "        loss = loss + weights[\"u\"] * Lu\n",
    "\n",
    "    # Strains (if available in CSV)\n",
    "    if weights.get(\"E\", 0.0) > 0 and (E11b is not None or E22b is not None or E12b is not None):\n",
    "        terms = []\n",
    "        if E11b is not None: terms.append((ux_pred - E11b)**2)\n",
    "        if E22b is not None: terms.append((vy_pred - E22b)**2)\n",
    "        if E12b is not None:\n",
    "            e12_pred = 0.5*(uy_pred + vx_pred)\n",
    "            terms.append((e12_pred - E12b)**2)\n",
    "        if terms:\n",
    "            LE = torch.mean(sum(terms))\n",
    "            loss = loss + weights[\"E\"] * LE\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c8fc4ee-4a01-4cca-b4a4-99178d1a4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn_hybrid(model, optimizer, n_epochs, n_points, L, W,\n",
    "                      train_dl,\n",
    "                      w_pde=1.0, w_bc=50.0, w_data=1.0,\n",
    "                      data_weights={\"u\":1.0, \"E\":0.0}):\n",
    "    \"\"\"\n",
    "    Hybrid training: physics + BC + data.\n",
    "    - train_dl: DataLoader over your CSV tensors\n",
    "    - data_weights: choose what to supervise from CSV\n",
    "        {\"u\":1.0, \"E\":0.0}        -> only displacements\n",
    "        {\"u\":1.0, \"E\":0.5}        -> displacements + strains\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    history = []\n",
    "\n",
    "    # iterate over epochs\n",
    "    data_iter = iter(train_dl)\n",
    "    for ep in range(n_epochs):\n",
    "        # --- (1) PDE collocation points (interior) ---\n",
    "        x = torch.rand(n_points,1, device=device)*L - L/2\n",
    "        y = torch.rand(n_points,1, device=device)*W - W/2\n",
    "\n",
    "        lp = physics_loss(model, x, y)             # PDE + compatibility\n",
    "        lb = boundary_condition_loss(model, L, W)   # BC residuals\n",
    "\n",
    "        # --- (2) Supervised batch from CSV nodes ---\n",
    "        try:\n",
    "            batch = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(train_dl)\n",
    "            batch = next(data_iter)\n",
    "\n",
    "        # (Ensure tensors on same device; if your dataset already puts them on device, this is cheap)\n",
    "        batch = {k: (v.to(device) if v is not None else None) for k, v in batch.items()}\n",
    "\n",
    "        ld = data_loss_uvE(model, batch, data_weights)  # your integrated data loss\n",
    "\n",
    "        # --- (3) Total loss & step ---\n",
    "        loss = w_pde*lp + w_bc*lb + w_data*ld\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        history.append([loss.item(), lp.item(), lb.item(), ld.item()])\n",
    "\n",
    "        if ep % 500 == 0:\n",
    "            print(f\"[hybrid] ep {ep:5d} | total {loss.item():.3e} | pde {lp.item():.3e} | bc {lb.item():.3e} | data {ld.item():.3e}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a764d4-7546-4505-9dd8-3e73ad9964c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 │ Total: 6.767e+01 │ PDE+comp: 1.180e+00 │ BC: 1.330e+00\n",
      "Epoch   500 │ Total: 5.998e-04 │ PDE+comp: 4.628e-04 │ BC: 2.740e-06\n",
      "Epoch  1000 │ Total: 2.446e-04 │ PDE+comp: 1.907e-04 │ BC: 1.078e-06\n",
      "Epoch  1500 │ Total: 1.288e-04 │ PDE+comp: 1.010e-04 │ BC: 5.560e-07\n",
      "Epoch  2000 │ Total: 7.602e-05 │ PDE+comp: 5.708e-05 │ BC: 3.789e-07\n",
      "Epoch  2500 │ Total: 5.226e-05 │ PDE+comp: 3.910e-05 │ BC: 2.630e-07\n",
      "Epoch  3000 │ Total: 7.535e-05 │ PDE+comp: 3.007e-05 │ BC: 9.055e-07\n",
      "Epoch  3500 │ Total: 3.778e-05 │ PDE+comp: 2.382e-05 │ BC: 2.792e-07\n",
      "Epoch  4000 │ Total: 1.269e-04 │ PDE+comp: 1.947e-05 │ BC: 2.150e-06\n",
      "Epoch  4500 │ Total: 3.242e-05 │ PDE+comp: 2.160e-05 │ BC: 2.164e-07\n",
      "Epoch  5000 │ Total: 5.617e-05 │ PDE+comp: 1.745e-05 │ BC: 7.743e-07\n",
      "Epoch  5500 │ Total: 1.063e-04 │ PDE+comp: 3.195e-05 │ BC: 1.488e-06\n",
      "Epoch  6000 │ Total: 1.541e-04 │ PDE+comp: 2.402e-05 │ BC: 2.602e-06\n",
      "Epoch  6500 │ Total: 4.426e-05 │ PDE+comp: 2.005e-05 │ BC: 4.842e-07\n",
      "Epoch  7000 │ Total: 1.720e-02 │ PDE+comp: 1.711e-05 │ BC: 3.436e-04\n",
      "Epoch  7500 │ Total: 1.762e-02 │ PDE+comp: 1.625e-05 │ BC: 3.520e-04\n",
      "Epoch  8000 │ Total: 3.543e-02 │ PDE+comp: 2.425e-05 │ BC: 7.081e-04\n",
      "Epoch  8500 │ Total: 1.782e-04 │ PDE+comp: 1.244e-05 │ BC: 3.314e-06\n",
      "Epoch  9000 │ Total: 8.662e-05 │ PDE+comp: 1.039e-05 │ BC: 1.525e-06\n",
      "Epoch  9500 │ Total: 1.251e-02 │ PDE+comp: 1.016e-05 │ BC: 2.500e-04\n"
     ]
    }
   ],
   "source": [
    "# initialize and run\n",
    "model     = PINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 10000\n",
    "n_points = 1000\n",
    "loss_history = train_pinn(model, optimizer, n_epochs, n_points, L, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0faa1225-e72a-4432-9401-ab65a2675a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model weights saved to data_driven_pinn_elasticity.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"data_driven_pinn_elasticity.pth\")\n",
    "print(\"✅ Model weights saved to data_driven_pinn_elasticity.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3620a62-9d53-4776-853c-479452637c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "# ─── 1) Define PINN Architecture ─────────────────────────────────────────────\n",
    "L, W = 1.0, 0.5\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(256, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        xi  = 2.0 * x / L\n",
    "        eta = 2.0 * y / W\n",
    "        return self.net(torch.cat([xi, eta], dim=1))\n",
    "\n",
    "# ─── 2) Load Trained Weights ─────────────────────────────────────────────────\n",
    "model = PINN()\n",
    "state = torch.load(\"pinn_elasticity.pth\", map_location=\"cpu\", weights_only=True)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# ─── 3) Load and Clean COMSOL CSV ────────────────────────────────────────────\n",
    "csv_path = '/Users/murat/Downloads/data.csv'  # keep filename unchanged\n",
    "# Read CSV, skip lines starting with '%'\n",
    "df = pd.read_csv(csv_path, comment='%')\n",
    "# Clean column names: strip whitespace and leading '%'\n",
    "df.columns = df.columns.str.strip().str.lstrip('%').str.strip()\n",
    "\n",
    "# Columns should now be: X, Y, u1 (cm), u2 (cm), ...\n",
    "X = df['X'].values\n",
    "Y = df['Y'].values\n",
    "u_act = df['u1 (cm)'].values  # actual u-displacement (cm)\n",
    "v_act = df['u2 (cm)'].values  # actual v-displacement (cm)\n",
    "\n",
    "# ─── 4) Prepare Input Tensors ───────────────────────────────────────────────\n",
    "x_t = torch.tensor(X, dtype=torch.float32).reshape(-1,1)\n",
    "y_t = torch.tensor(Y, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "# ─── 5) Forward Pass: Predict u, v ─────────────────────────────────────────\n",
    "out = model(x_t, y_t)\n",
    "# network outputs: [u_pred, v_pred, u_x, u_y, v_x, v_y]\n",
    "u_pred = out[:,0].detach().numpy().flatten()\n",
    "v_pred = out[:,1].detach().numpy().flatten()\n",
    "\n",
    "df['u_pred'] = u_pred  # predicted u (cm)\n",
    "df['v_pred'] = v_pred  # predicted v (cm)\n",
    "\n",
    "# ─── 6) Compute Absolute & Percent Errors ───────────────────────────────────\n",
    "df['err_u'] = np.abs(u_act - df['u_pred'])\n",
    "df['err_v'] = np.abs(v_act - df['v_pred'])\n",
    "\n",
    "df['pct_err_u'] = np.where(\n",
    "    np.isclose(u_act, 0),\n",
    "    0,\n",
    "    df['err_u'] / np.abs(u_act) * 100\n",
    ")\n",
    "df['pct_err_v'] = np.where(\n",
    "    np.isclose(v_act, 0),\n",
    "    0,\n",
    "    df['err_v'] / np.abs(v_act) * 100\n",
    ")\n",
    "\n",
    "# ─── 7) Display Percent Errors ───────────────────────────────────────────────\n",
    "print(f\"Mean % error in u: {df['pct_err_u'].mean():.2f}%\")\n",
    "print(f\"Mean % error in v: {df['pct_err_v'].mean():.2f}%\")\n",
    "\n",
    "# ─── 8) Plotting Helpers ───────────────────────────────────────────────────\n",
    "triang = mtri.Triangulation(X, Y)\n",
    "def plot_contour(field, title, units=''):\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    cf = ax.tricontourf(triang, field, levels=100, cmap='viridis')\n",
    "    fig.colorbar(cf, ax=ax, label=units)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ─── 9) Visualize Absolute Errors ───────────────────────────────────────────\n",
    "plot_contour(df['err_u'], 'Absolute Error in u', '|u_act - u_pred|')\n",
    "plot_contour(df['err_v'], 'Absolute Error in v', '|v_act - v_pred|')\n",
    "\n",
    "# ─── 10) Parity Plots ──────────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "axes[0].scatter(df['u1 (cm)'], df['u_pred'], s=10)\n",
    "axes[0].plot([\n",
    "    df['u1 (cm)'].min(), df['u1 (cm)'].max()\n",
    "], [\n",
    "    df['u1 (cm)'].min(), df['u1 (cm)'].max()\n",
    "], 'k--')\n",
    "axes[0].set_xlabel('u1 (cm)')\n",
    "axes[0].set_ylabel('u_pred (cm)')\n",
    "axes[0].set_title('Parity Plot: u')\n",
    "\n",
    "axes[1].scatter(df['u2 (cm)'], df['v_pred'], s=10)\n",
    "axes[1].plot([\n",
    "    df['u2 (cm)'].min(), df['u2 (cm)'].max()\n",
    "], [\n",
    "    df['u2 (cm)'].min(), df['u2 (cm)'].max()\n",
    "], 'k--')\n",
    "axes[1].set_xlabel('u2 (cm)')\n",
    "axes[1].set_ylabel('v_pred (cm)')\n",
    "axes[1].set_title('Parity Plot: v')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
