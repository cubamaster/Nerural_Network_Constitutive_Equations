{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82579d30-a0a5-465a-9b1a-d270ac8b0d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, PDE_x: 1.036318e-01, PDE_y: 1.102702e-02, PDE(total): 1.113065e+01, BC: 2.969987e-03, Total: 1.113362e+01\n",
      "Epoch 500, PDE_x: 2.550296e-04, PDE_y: 2.381111e-06, PDE(total): 2.636141e-03, BC: 3.288079e-07, Total: 2.636470e-03\n",
      "Epoch 1000, PDE_x: 1.029840e-04, PDE_y: 1.492643e-06, PDE(total): 1.595627e-03, BC: 3.018668e-07, Total: 1.595929e-03\n",
      "Epoch 1500, PDE_x: 9.108472e-05, PDE_y: 7.151236e-07, PDE(total): 8.062084e-04, BC: 2.789385e-07, Total: 8.064873e-04\n",
      "Epoch 2000, PDE_x: 7.870488e-05, PDE_y: 4.067912e-07, PDE(total): 4.854960e-04, BC: 2.665641e-07, Total: 4.857626e-04\n",
      "Epoch 2500, PDE_x: 6.335396e-05, PDE_y: 2.677481e-07, PDE(total): 3.311021e-04, BC: 2.586939e-07, Total: 3.313608e-04\n",
      "Epoch 3000, PDE_x: 5.953158e-05, PDE_y: 1.569299e-07, PDE(total): 2.164615e-04, BC: 2.518604e-07, Total: 2.167133e-04\n",
      "Epoch 3500, PDE_x: 4.441489e-05, PDE_y: 1.099061e-07, PDE(total): 1.543210e-04, BC: 2.447799e-07, Total: 1.545658e-04\n",
      "Epoch 4000, PDE_x: 4.202103e-05, PDE_y: 9.436697e-08, PDE(total): 1.363880e-04, BC: 2.367813e-07, Total: 1.366248e-04\n",
      "Epoch 4500, PDE_x: 2.934389e-05, PDE_y: 7.614129e-08, PDE(total): 1.054852e-04, BC: 2.288221e-07, Total: 1.057140e-04\n",
      "Epoch 5000, PDE_x: 2.164989e-05, PDE_y: 6.949007e-08, PDE(total): 9.113997e-05, BC: 2.209355e-07, Total: 9.136090e-05\n",
      "Epoch 5500, PDE_x: 2.300095e-05, PDE_y: 8.346770e-08, PDE(total): 1.064687e-04, BC: 2.042466e-07, Total: 1.066729e-04\n",
      "Epoch 6000, PDE_x: 1.894093e-05, PDE_y: 7.972031e-07, PDE(total): 8.161441e-04, BC: 1.864466e-07, Total: 8.163305e-04\n",
      "Epoch 6500, PDE_x: 1.194728e-05, PDE_y: 2.109634e-07, PDE(total): 2.229107e-04, BC: 1.741398e-07, Total: 2.230848e-04\n",
      "Epoch 7000, PDE_x: 1.770513e-05, PDE_y: 7.433761e-05, PDE(total): 7.435531e-02, BC: 1.353430e-07, Total: 7.435545e-02\n",
      "Epoch 7500, PDE_x: 5.581909e-06, PDE_y: 4.280754e-08, PDE(total): 4.838945e-05, BC: 1.214437e-07, Total: 4.851089e-05\n",
      "Epoch 8000, PDE_x: 1.217634e-05, PDE_y: 5.933803e-07, PDE(total): 6.055566e-04, BC: 2.735103e-07, Total: 6.058301e-04\n",
      "Epoch 8500, PDE_x: 3.660842e-06, PDE_y: 2.286559e-07, PDE(total): 2.323168e-04, BC: 9.679017e-08, Total: 2.324136e-04\n",
      "Epoch 9000, PDE_x: 1.539625e-06, PDE_y: 8.963254e-09, PDE(total): 1.050288e-05, BC: 6.821617e-08, Total: 1.057110e-05\n",
      "Epoch 9500, PDE_x: 1.291396e-06, PDE_y: 5.594538e-09, PDE(total): 6.885934e-06, BC: 5.508792e-08, Total: 6.941022e-06\n",
      "         X     Y    u_x_actual    u_y_actual  u_x_pred  u_y_pred  \\\n",
      "0    -0.50 -0.25  1.483633e-19  1.263433e-19  0.000000 -0.000000   \n",
      "1    -0.48 -0.25  9.101041e-04  9.363998e-04  0.000494 -0.000011   \n",
      "2    -0.50 -0.23 -1.530000e-20 -4.190000e-20  0.000000 -0.000000   \n",
      "3    -0.48 -0.23  5.332043e-04  6.506182e-04  0.000494 -0.000011   \n",
      "4    -0.50 -0.21  2.321675e-21 -6.630000e-21  0.000000 -0.000000   \n",
      "...    ...   ...           ...           ...       ...       ...   \n",
      "1321  0.48  0.23  2.446680e-02 -6.510000e-04  0.024775  0.000244   \n",
      "1322  0.50  0.21  2.500000e-02  3.680167e-18  0.025266 -0.000000   \n",
      "1323  0.48  0.25  2.408990e-02 -9.360000e-04  0.024797  0.000272   \n",
      "1324  0.50  0.23  2.500000e-02  1.768693e-18  0.025289 -0.000000   \n",
      "1325  0.50  0.25  2.500000e-02  2.080774e-17  0.025312 -0.000000   \n",
      "\n",
      "         error_u_x     error_u_y  percent_error_u_x  percent_error_u_y  \n",
      "0     1.483633e-19  1.263433e-19           0.000000           0.000000  \n",
      "1     4.158413e-04  9.477198e-04          45.691619         101.208882  \n",
      "2     1.530000e-20  4.190000e-20           0.000000           0.000000  \n",
      "3     3.908214e-05  6.612663e-04           7.329674         101.636615  \n",
      "4     2.321675e-21  6.630000e-21           0.000000           0.000000  \n",
      "...            ...           ...                ...                ...  \n",
      "1321  3.078600e-04  8.949947e-04           1.258277         137.479987  \n",
      "1322  2.662804e-04  3.680167e-18           1.065122           0.000000  \n",
      "1323  7.066328e-04  1.208401e-03           2.933316         129.102720  \n",
      "1324  2.892971e-04  1.768693e-18           1.157188           0.000000  \n",
      "1325  3.117979e-04  2.080774e-17           1.247191           0.000000  \n",
      "\n",
      "[1326 rows x 10 columns]\n",
      "Average Percent Error for u_x: 3.69%\n",
      "Average Percent Error for u_y: 108.13%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "L, W = 1.0, 0.5  # Length and width of the domain (in cm)\n",
    "lambda_ = 5.0e9  # Elastic constant (Pa)\n",
    "mu = 5.0e9       # Shear modulus (Pa)\n",
    "h = 1.0          # Thickness (cm)\n",
    "\n",
    "########################\n",
    "# Two separate PINNs   #\n",
    "########################\n",
    "class PINN_Ux(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN_Ux, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        inputs = torch.cat([x, y], dim=1)\n",
    "        raw_out = self.net(inputs).squeeze(dim=1)\n",
    "\n",
    "        # Enforce (x+0.5) scaling to mimic the original code\n",
    "        enforced_ux = (x.flatten() + 0.5) * raw_out\n",
    "        return enforced_ux.view(-1, 1)\n",
    "\n",
    "class PINN_Uy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN_Uy, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Softplus(beta=10),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        inputs = torch.cat([x, y], dim=1)\n",
    "        raw_out = self.net(inputs).squeeze(dim=1)\n",
    "\n",
    "        # Enforce (x+0.5) scaling for uy as well\n",
    "        enforced_uy = (x.flatten() + 0.5) * raw_out\n",
    "\n",
    "        # The original code sets u_y=0 if x=+0.5\n",
    "        corner_mask = (x[:, 0] == 0.5)\n",
    "        enforced_uy[corner_mask] = 0.0\n",
    "        return enforced_uy.view(-1, 1)\n",
    "\n",
    "##########################################\n",
    "# Helper to get [u_x, u_y] from 2 models #\n",
    "##########################################\n",
    "def get_u(model_u_x, model_u_y, x, y):\n",
    "    u_x_pred = model_u_x(x, y)  # shape (N,1)\n",
    "    u_y_pred = model_u_y(x, y)  # shape (N,1)\n",
    "    return torch.cat([u_x_pred, u_y_pred], dim=1)  # shape (N,2)\n",
    "\n",
    "##############################\n",
    "# Strain and stress (same)   #\n",
    "##############################\n",
    "def strain_tensor(u_x, u_y, x, y):\n",
    "    u_x_x = torch.autograd.grad(u_x, x,\n",
    "                                grad_outputs=torch.ones_like(u_x),\n",
    "                                retain_graph=True,\n",
    "                                create_graph=True)[0]\n",
    "    u_y_y = torch.autograd.grad(u_y, y,\n",
    "                                grad_outputs=torch.ones_like(u_y),\n",
    "                                retain_graph=True,\n",
    "                                create_graph=True)[0]\n",
    "    u_x_y = torch.autograd.grad(u_x, y,\n",
    "                                grad_outputs=torch.ones_like(u_x),\n",
    "                                retain_graph=True,\n",
    "                                create_graph=True)[0]\n",
    "    u_y_x = torch.autograd.grad(u_y, x,\n",
    "                                grad_outputs=torch.ones_like(u_y),\n",
    "                                retain_graph=True,\n",
    "                                create_graph=True)[0]\n",
    "\n",
    "    E_xx = u_x_x\n",
    "    E_yy = u_y_y\n",
    "    E_xy = 0.5 * (u_x_y + u_y_x)\n",
    "    return E_xx, E_yy, E_xy\n",
    "\n",
    "def stress_tensor(E_xx, E_yy, E_xy):\n",
    "    scale_factor = 1e9\n",
    "    trace_E = E_xx + E_yy\n",
    "    sigma_xx = h * ((lambda_ / scale_factor) * trace_E + 2.0 * (mu / scale_factor) * E_xx)\n",
    "    sigma_yy = h * ((lambda_ / scale_factor) * trace_E + 2.0 * (mu / scale_factor) * E_yy)\n",
    "    sigma_xy = h * (2.0 * (mu / scale_factor) * E_xy)\n",
    "    return sigma_xx, sigma_yy, sigma_xy\n",
    "\n",
    "############################################\n",
    "# Physics (PDE) loss with separate x & y   #\n",
    "############################################\n",
    "def physics_loss(model_u_x, model_u_y, x, y):\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "\n",
    "    # Combined displacement from the two sub-networks\n",
    "    u = get_u(model_u_x, model_u_y, x, y)\n",
    "    u_x, u_y = u[:, 0:1], u[:, 1:2]\n",
    "\n",
    "    # Strain\n",
    "    E_xx, E_yy, E_xy = strain_tensor(u_x, u_y, x, y)\n",
    "    # Stress\n",
    "    sigma_xx, sigma_yy, sigma_xy = stress_tensor(E_xx, E_yy, E_xy)\n",
    "\n",
    "    # PDE residuals\n",
    "    sigma_xx_x = torch.autograd.grad(sigma_xx, x,\n",
    "                                     grad_outputs=torch.ones_like(sigma_xx),\n",
    "                                     retain_graph=True,\n",
    "                                     create_graph=True)[0]\n",
    "    sigma_xy_y = torch.autograd.grad(sigma_xy, y,\n",
    "                                     grad_outputs=torch.ones_like(sigma_xy),\n",
    "                                     retain_graph=True,\n",
    "                                     create_graph=True)[0]\n",
    "    sigma_yy_y = torch.autograd.grad(sigma_yy, y,\n",
    "                                     grad_outputs=torch.ones_like(sigma_yy),\n",
    "                                     retain_graph=True,\n",
    "                                     create_graph=True)[0]\n",
    "    sigma_xy_x = torch.autograd.grad(sigma_xy, x,\n",
    "                                     grad_outputs=torch.ones_like(sigma_xy),\n",
    "                                     retain_graph=True,\n",
    "                                     create_graph=True)[0]\n",
    "\n",
    "    # Separate PDE residual for x and y\n",
    "    residual_x = sigma_xx_x + sigma_xy_y\n",
    "    residual_y = sigma_yy_y + sigma_xy_x\n",
    "\n",
    "    # Mean squared for each component\n",
    "    loss_equilibrium_x = torch.mean(residual_x**2)\n",
    "    loss_equilibrium_y = torch.mean(residual_y**2)\n",
    "\n",
    "    # Give the y-residual 1e3 heavier weight\n",
    "    loss_equilibrium = loss_equilibrium_x + 1e3 * loss_equilibrium_y\n",
    "\n",
    "    return loss_equilibrium, loss_equilibrium_x, loss_equilibrium_y\n",
    "\n",
    "##################################\n",
    "# Boundary conditions (same)     #\n",
    "##################################\n",
    "def boundary_condition_loss(model_u_x, model_u_y, L, W):\n",
    "    # Boundary A: u_x = 0, u_y = 0 at x = -L/2\n",
    "    y_A = torch.linspace(-W / 2, W / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    x_A = -L / 2 * torch.ones_like(y_A, requires_grad=True)\n",
    "    u_A = get_u(model_u_x, model_u_y, x_A, y_A)\n",
    "    loss_A = torch.mean(u_A**2)\n",
    "\n",
    "    # Boundary D: u_x = 0.025 * L, u_y = 0 at x = L/2\n",
    "    y_D = torch.linspace(-W / 2, W / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    x_D = L / 2 * torch.ones_like(y_D, requires_grad=True)\n",
    "    u_D = get_u(model_u_x, model_u_y, x_D, y_D)\n",
    "    loss_D = torch.mean((u_D[:, 1:2])**2 + (u_D[:, 0:1] - 0.025 * L)**2)\n",
    "\n",
    "    # Boundary C (y=0) => enforce u_y=0 at y=0\n",
    "    x_bottom = torch.linspace(-L/2, L/2, 200).reshape(-1,1).requires_grad_()\n",
    "    y_bottom = torch.zeros_like(x_bottom, requires_grad=True)\n",
    "    u_bottom = get_u(model_u_x, model_u_y, x_bottom, y_bottom)\n",
    "    loss_C = torch.mean(u_bottom[:,1:2]**2)\n",
    "\n",
    "    # Boundary B: traction-free (sigma_yy = sigma_xy = 0) at y = W/2\n",
    "    x_B = torch.linspace(-L / 2, L / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    y_B = W / 2 * torch.ones_like(x_B, requires_grad=True)\n",
    "    u_B = get_u(model_u_x, model_u_y, x_B, y_B)\n",
    "    u_B_x, u_B_y = u_B[:, 0:1], u_B[:, 1:2]\n",
    "    E_xx_B, E_yy_B, E_xy_B = strain_tensor(u_B_x, u_B_y, x_B, y_B)\n",
    "    sigma_xx_B, sigma_yy_B, sigma_xy_B = stress_tensor(E_xx_B, E_yy_B, E_xy_B)\n",
    "    loss_B = torch.mean(sigma_yy_B**2 + sigma_xy_B**2)\n",
    "\n",
    "    return loss_A + loss_D + (loss_B / 1e18) + loss_C\n",
    "\n",
    "##########################################\n",
    "# Training: now logs PDE_x and PDE_y     #\n",
    "##########################################\n",
    "def train_pinn(model_u_x, model_u_y, optimizer, n_epochs, n_points, L, W):\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Sample points in the top domain\n",
    "        x = (torch.rand((n_points,1)) * L) - (L/2)  # [-L/2, +L/2]\n",
    "        y = torch.rand((n_points,1)) * (W/2)       # [0, W/2]\n",
    "\n",
    "        loss_pde, loss_pde_x, loss_pde_y = physics_loss(model_u_x, model_u_y, x, y)\n",
    "        loss_bc  = boundary_condition_loss(model_u_x, model_u_y, L, W)\n",
    "\n",
    "        # Combine PDE + BC\n",
    "        loss = loss_pde + loss_bc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "        if epoch % 500 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, \"\n",
    "                f\"PDE_x: {loss_pde_x.item():.6e}, \"\n",
    "                f\"PDE_y: {loss_pde_y.item():.6e}, \"\n",
    "                f\"PDE(total): {loss_pde.item():.6e}, \"\n",
    "                f\"BC: {loss_bc.item():.6e}, \"\n",
    "                f\"Total: {loss.item():.6e}\"\n",
    "            )\n",
    "\n",
    "    return loss_history\n",
    "\n",
    "#####################\n",
    "# Instantiate model #\n",
    "#####################\n",
    "model_u_x = PINN_Ux()\n",
    "model_u_y = PINN_Uy()\n",
    "\n",
    "# Single optimizer for both\n",
    "params = list(model_u_x.parameters()) + list(model_u_y.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Train\n",
    "n_epochs = 10000\n",
    "n_points = 1000\n",
    "loss_history = train_pinn(model_u_x, model_u_y, optimizer, n_epochs, n_points, L, W)\n",
    "\n",
    "#################\n",
    "# Compare to CSV #\n",
    "#################\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/murat/Downloads/data.csv'\n",
    "comparison_data = pd.read_csv(file_path)\n",
    "\n",
    "x_vals = torch.tensor(comparison_data['X'].values, dtype=torch.float32).reshape(-1,1)\n",
    "y_vals = torch.tensor(comparison_data['Y'].values, dtype=torch.float32).reshape(-1,1)\n",
    "u_x_actual = comparison_data['u_x_actual'].values\n",
    "u_y_actual = comparison_data['u_y_actual'].values\n",
    "\n",
    "y_abs = y_vals.abs()\n",
    "\n",
    "model_u_x.eval()\n",
    "model_u_y.eval()\n",
    "with torch.no_grad():\n",
    "    u_pred_top = get_u(model_u_x, model_u_y, x_vals, y_abs)\n",
    "\n",
    "# Mirror for the bottom part\n",
    "u_pred = u_pred_top.clone()\n",
    "mask_bottom = (y_vals > 0).view(-1)\n",
    "u_pred[mask_bottom, 1] *= -1.0\n",
    "\n",
    "u_x_pred = u_pred[:, 0].numpy()\n",
    "u_y_pred = u_pred[:, 1].numpy()\n",
    "\n",
    "comparison_data['u_x_pred'] = u_x_pred\n",
    "comparison_data['u_y_pred'] = u_y_pred\n",
    "comparison_data['error_u_x'] = abs(u_x_actual - u_x_pred)\n",
    "comparison_data['error_u_y'] = abs(u_y_actual - u_y_pred)\n",
    "\n",
    "def safe_percent_error(a, p):\n",
    "    if np.isclose(a, 0.0):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return abs(a - p) / abs(a) * 100.0\n",
    "\n",
    "comparison_data['percent_error_u_x'] = [\n",
    "    safe_percent_error(a, p) for a, p in zip(u_x_actual, u_x_pred)\n",
    "]\n",
    "comparison_data['percent_error_u_y'] = [\n",
    "    safe_percent_error(a, p) for a, p in zip(u_y_actual, u_y_pred)\n",
    "]\n",
    "\n",
    "print(comparison_data)\n",
    "\n",
    "avg_percent_error_x = comparison_data['percent_error_u_x'].mean()\n",
    "avg_percent_error_y = comparison_data['percent_error_u_y'].mean()\n",
    "\n",
    "print(f\"Average Percent Error for u_x: {avg_percent_error_x:.2f}%\")\n",
    "print(f\"Average Percent Error for u_y: {avg_percent_error_y:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c60005-95dc-48b8-b9a0-efec569b966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
